name: CD Pipeline

on:
  push:
    branches: [main]
  workflow_dispatch:

permissions:
  contents: read
  id-token: write

jobs:
  # JOB 1: Build Docker image (and optionally push)
  build-images:
    runs-on: ubuntu-latest
    outputs:
      image-tag: banking-airflow:latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Docker registry (only if creds provided)
        uses: docker/login-action@v3
        if: ${{ secrets.DOCKER_USERNAME }}
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}

      - name: Build Airflow image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./dockerfile-airflow.dockerfile
          push: ${{ secrets.DOCKER_USERNAME && secrets.DOCKER_PASSWORD != '' }}
          tags: ${{ secrets.DOCKER_USERNAME && secrets.DOCKER_USERNAME != '' && format('{0}/banking-airflow:latest', secrets.DOCKER_USERNAME) || 'banking-airflow:latest' }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

  # JOB 2: Deploy dbt to Production
  deploy-dbt:
    runs-on: ubuntu-latest
    needs: [build-images]
    environment:
      name: production
      url: https://app.snowflake.com
    steps:
      - uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"
          cache: "pip"

      - name: Install dbt (production version)
        run: |
          python -m pip install --upgrade pip
          pip install "dbt-core==1.10.15" "dbt-snowflake==1.10.3"

      - name: Setup dbt profile (prod) using secrets
        run: |
          mkdir -p ~/.dbt
          cat > ~/.dbt/profiles.yml <<EOL
banking:
  target: prod
  outputs:
    prod:
      type: snowflake
      account: ${{ secrets.SNOWFLAKE_ACCOUNT }}
      user: ${{ secrets.SNOWFLAKE_USER }}
      password: ${{ secrets.SNOWFLAKE_PASSWORD }}
      role: ACCOUNTADMIN
      database: banking
      warehouse: ${{ secrets.SNOWFLAKE_WAREHOUSE }}
      schema: prod
      threads: 4
      client_session_keep_alive: true
      query_tag: github_actions_prod
EOL

      - name: cd to dbt project and run dbt
        run: |
          cd banking
          dbt deps || true
          dbt debug --profiles-dir ~/.dbt
          dbt seed --profiles-dir ~/.dbt --target prod || true
          dbt run --select staging --profiles-dir ~/.dbt --target prod
          dbt snapshot --profiles-dir ~/.dbt --target prod
          dbt run --select marts.dimensions --profiles-dir ~/.dbt --target prod
          dbt run --select marts.facts --profiles-dir ~/.dbt --target prod
          dbt test --profiles-dir ~/.dbt --target prod

      - name: Upload dbt artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: dbt-artifacts
          path: |
            banking/target/manifest.json
            banking/target/run_results.json
            banking/target/catalog.json
          retention-days: 30

  # JOB 3: Optional infra deploy/notify (manual or if commit message contains [infra])
  deploy-infrastructure:
    runs-on: ubuntu-latest
    needs: [build-images]
    if: ${{ github.event_name == 'workflow_dispatch' || (github.event_name == 'push' && contains(github.event.head_commit.message, '[infra]')) }}
    steps:
      - uses: actions/checkout@v4
      - name: Validate docker-compose.yml (local check)
        run: docker-compose -f docker-compose.yml config
      - name: Notify infra change
        run: echo "Infrastructure change detected. Review and apply manually."

  # JOB 4: Post deployment data quality checks
  data-quality-checks:
    runs-on: ubuntu-latest
    needs: [deploy-dbt]
    steps:
      - uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install dependencies
        run: python -m pip install --upgrade pip && pip install snowflake-connector-python pandas

      - name: Run simple data quality checks
        env:
          SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
          SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE_USER }}
          SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
          SNOWFLAKE_WAREHOUSE: ${{ secrets.SNOWFLAKE_WAREHOUSE }}
        run: |
          python - <<PY
import os, snowflake.connector
conn = snowflake.connector.connect(
    account=os.environ['SNOWFLAKE_ACCOUNT'],
    user=os.environ['SNOWFLAKE_USER'],
    password=os.environ['SNOWFLAKE_PASSWORD'],
    warehouse=os.environ['SNOWFLAKE_WAREHOUSE'],
    database='banking',
    schema='prod'
)
cur = conn.cursor()
for t in ['dim_customers','dim_accounts','fact_transactions']:
    cur.execute(f"select count(*) from {t}")
    print(t, cur.fetchone()[0])
cur.close(); conn.close()
PY

  # JOB 5: Notify (summary)
  notify:
    runs-on: ubuntu-latest
    needs: [deploy-dbt, data-quality-checks]
    if: always()
    steps:
      - name: Deployment summary
        run: |
          echo "## Deployment Summary" >> $GITHUB_STEP_SUMMARY
          echo "- Branch: ${{ github.ref_name }}" >> $GITHUB_STEP_SUMMARY
          echo "- Commit: ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
          echo "- Deployer: ${{ github.actor }}" >> $GITHUB_STEP_SUMMARY
