name: CD Pipeline

on:
  push:
    branches: [main]  # Deploy only from main branch
  workflow_dispatch:  # Allow manual trigger

jobs:
  # ========================================
  # JOB 1: Build and Push Docker Images
  # ========================================
  build-images:
    name: Build Docker Images
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Docker Hub (optional)
        uses: docker/login-action@v3
        if: github.event_name != 'pull_request'
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}
        continue-on-error: true

      - name: Build Airflow image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./dockerfile-airflow.dockerfile
          push: false
          tags: banking-airflow:latest
          cache-from: type=gha
          cache-to: type=gha,mode=max

  # ========================================
  # JOB 2: Deploy dbt to Production
  # ========================================
  deploy-dbt:
    name: Deploy dbt Models to Production
    runs-on: ubuntu-latest
    needs: [build-images]
    environment:
      name: production
      url: https://app.snowflake.com
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"
          cache: 'pip'

      - name: Install dbt
        run: |
          python -m pip install --upgrade pip
          pip install dbt-core==1.7.4 dbt-snowflake==1.7.1

      - name: Setup dbt profile (production)
        run: |
          mkdir -p ~/.dbt
          cat > ~/.dbt/profiles.yml <<EOL
          banking:
            target: prod
            outputs:
              prod:
                type: snowflake
                account: ${{ secrets.SNOWFLAKE_ACCOUNT }}
                user: ${{ secrets.SNOWFLAKE_USER }}
                password: ${{ secrets.SNOWFLAKE_PASSWORD }}
                role: ACCOUNTADMIN
                database: banking
                warehouse: ${{ secrets.SNOWFLAKE_WAREHOUSE }}
                schema: prod
                threads: 4
                client_session_keep_alive: true
                query_tag: github_actions_prod
          EOL

      - name: Install dbt dependencies
        run: |
          cd banking
          dbt deps || echo "No packages to install"

      - name: dbt debug (test connection)
        run: |
          cd banking
          dbt debug --profiles-dir ~/.dbt

      - name: dbt seed (load reference data)
        run: |
          cd banking
          dbt seed --profiles-dir ~/.dbt --target prod
        continue-on-error: true

      - name: dbt run - staging models
        run: |
          cd banking
          dbt run --select staging --profiles-dir ~/.dbt --target prod

      - name: dbt snapshot - SCD2 tables
        run: |
          cd banking
          dbt snapshot --profiles-dir ~/.dbt --target prod

      - name: dbt run - dimension models
        run: |
          cd banking
          dbt run --select marts.dimensions --profiles-dir ~/.dbt --target prod

      - name: dbt run - fact models
        run: |
          cd banking
          dbt run --select marts.facts --profiles-dir ~/.dbt --target prod

      - name: dbt test - data quality tests
        run: |
          cd banking
          dbt test --profiles-dir ~/.dbt --target prod

      - name: dbt docs generate
        run: |
          cd banking
          dbt docs generate --profiles-dir ~/.dbt --target prod

      - name: Upload dbt artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: dbt-artifacts
          path: |
            banking/target/manifest.json
            banking/target/run_results.json
            banking/target/catalog.json
          retention-days: 30

  # ========================================
  # JOB 3: Deploy Infrastructure Changes
  # ========================================
  deploy-infrastructure:
    name: Deploy Infrastructure Updates
    runs-on: ubuntu-latest
    needs: [build-images]
    if: github.event_name == 'workflow_dispatch' || contains(github.event.head_commit.message, '[infra]')
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Validate docker-compose.yml
        run: |
          docker-compose config

      - name: Create deployment notification
        run: |
          echo "Infrastructure changes detected"
          echo "Review docker-compose.yml changes manually"

  # ========================================
  # JOB 4: Data Quality Validation
  # ========================================
  data-quality-checks:
    name: Post-Deployment Data Quality
    runs-on: ubuntu-latest
    needs: [deploy-dbt]
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install dependencies
        run: |
          pip install snowflake-connector-python pandas

      - name: Run custom data quality checks
        run: |
          python -c "
          import snowflake.connector
          import os

          conn = snowflake.connector.connect(
              account=os.environ['SNOWFLAKE_ACCOUNT'],
              user=os.environ['SNOWFLAKE_USER'],
              password=os.environ['SNOWFLAKE_PASSWORD'],
              warehouse=os.environ['SNOWFLAKE_WAREHOUSE'],
              database='banking',
              schema='prod'
          )

          cursor = conn.cursor()

          # Check row counts
          tables = ['dim_customers', 'dim_accounts', 'fact_transactions']
          for table in tables:
              cursor.execute(f'SELECT COUNT(*) FROM {table}')
              count = cursor.fetchone()[0]
              print(f'{table}: {count} rows')
              if count == 0:
                  print(f'WARNING: {table} is empty!')

          cursor.close()
          conn.close()
          "
        env:
          SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
          SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE_USER }}
          SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
          SNOWFLAKE_WAREHOUSE: ${{ secrets.SNOWFLAKE_WAREHOUSE }}
        continue-on-error: true

  # ========================================
  # JOB 5: Notify Deployment Status
  # ========================================
  notify:
    name: Send Deployment Notifications
    runs-on: ubuntu-latest
    needs: [deploy-dbt, data-quality-checks]
    if: always()
    steps:
      - name: Create deployment summary
        run: |
          echo "## Deployment Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Branch:** ${{ github.ref_name }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Commit:** ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Author:** ${{ github.actor }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Timestamp:** $(date -u)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Jobs Status:" >> $GITHUB_STEP_SUMMARY
          echo "- dbt Deployment: ${{ needs.deploy-dbt.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Data Quality: ${{ needs.data-quality-checks.result }}" >> $GITHUB_STEP_SUMMARY

      - name: Send Slack notification (optional)
        if: secrets.SLACK_WEBHOOK_URL != ''
        run: |
          curl -X POST ${{ secrets.SLACK_WEBHOOK_URL }} \
            -H 'Content-Type: application/json' \
            -d '{
              "text": "Banking MDS Deployment",
              "blocks": [
                {
                  "type": "section",
                  "text": {
                    "type": "mrkdwn",
                    "text": "*Banking Modern Data Stack - Deployment Complete*\n\nBranch: `${{ github.ref_name }}`\nStatus: ${{ job.status }}\nCommit: ${{ github.sha }}"
                  }
                }
              ]
            }'
        continue-on-error: true